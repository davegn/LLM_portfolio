{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657e098a-212b-4f13-9225-981672365efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install googlesearch-python\n",
    "# !pip install -U crawl4ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddebc086-2040-4296-bc79-7a904df27b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crawl4ai\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from googlesearch import search\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "from playwright.async_api import async_playwright\n",
    "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
    "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
    "from crawl4ai import AsyncWebCrawler, CacheMode, BrowserConfig, CrawlerRunConfig, CacheMode\n",
    "\n",
    "home_dir = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853e5789-53ee-45ef-bcf8-a785f1dd35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'list LLM API provider and reviews'\n",
    "num_results = 10\n",
    "\n",
    "# local_model = \"qwen3-14b-mlx\"\n",
    "# local_api_key = 'None'\n",
    "# local_base_url = 'http://127.0.0.1:1234/v1'\n",
    "\n",
    "clean_up_model = \"gemini-2.0-flash-lite\"\n",
    "clean_up_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "clean_up_base_url = 'https://generativelanguage.googleapis.com/v1beta/openai/'\n",
    "\n",
    "report_model = \"gemini-2.0-flash\"\n",
    "report_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "report_base_url = 'https://generativelanguage.googleapis.com/v1beta/openai/'\n",
    "\n",
    "data_path = f'Reports extracted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881b5989-6b1b-4bbf-8d60-5687971bb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_url_from_google_search(topic, num_results):\n",
    "    list_of_urls = []\n",
    "    \n",
    "    google_url = search(topic, num_results=num_results+1,unique=True, region='sg', \n",
    "                          sleep_interval=5, advanced=False, safe=None)\n",
    "    for url in google_url:\n",
    "        list_of_urls.append(url)\n",
    "        \n",
    "    return list_of_urls[1:]\n",
    "\n",
    "async def scrape_site_clean_makedown(url):\n",
    "    print(url)\n",
    "    browser_config = BrowserConfig(browser_type=\"chromium\",  # Type of browser to simulate\n",
    "                                    headless=True,  # Whether to run in headless mode (no GUI)\n",
    "                                    verbose=True,  # Enable verbose logging)\n",
    "                                  )\n",
    "    \n",
    "    content_filter = PruningContentFilter()\n",
    "    markdown_generator = DefaultMarkdownGenerator(content_filter=content_filter)\n",
    "    config = CrawlerRunConfig(markdown_generator=markdown_generator)\n",
    "    \n",
    "    try:\n",
    "        async with AsyncWebCrawler(config=browser_config) as crawler:\n",
    "            scrape_data = await crawler.arun(url, config=config)\n",
    "    \n",
    "        return scrape_data.markdown.fit_markdown\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def call_llm(system_prompt, user_prompt, stream,\n",
    "            model, base_url, api_key, temperature=0.0):\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt,\n",
    "                \"role\": \"user\",\"content\": user_prompt}]\n",
    "    \n",
    "    openai = OpenAI(base_url=base_url, \n",
    "                          api_key=api_key)\n",
    "    if stream == True:\n",
    "\n",
    "        stream_response = openai.chat.completions.create(model = model,\n",
    "                                            messages = messages,\n",
    "                                            stream=stream,\n",
    "                                            temperature=temperature)\n",
    "        \n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        \n",
    "        for chunk in stream_response:\n",
    "                response += chunk.choices[0].delta.content or ''\n",
    "                response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "                update_display(Markdown(response), \n",
    "                               display_id=display_handle.display_id)\n",
    "            \n",
    "    else:\n",
    "        response = openai.chat.completions.create(model = model,\n",
    "                                            messages = messages, \n",
    "                                            temperature=temperature)\n",
    "\n",
    "        response = response.choices[0].message.content\n",
    "        \n",
    "    response_without_thinking = response.split('/think>')[-1]\n",
    "    \n",
    "    return response_without_thinking\n",
    "\n",
    "def get_report(topic, num_results, folder):\n",
    "    list_of_url = get_list_of_url_from_google_search(topic, num_results)\n",
    "\n",
    "    scrape_data_list = []\n",
    "    \n",
    "    for url in list_of_url:\n",
    "        result = asyncio.run(scrape_site_clean_makedown(url=url))\n",
    "        result += f\"URL : {url}\"\n",
    "        if len(result) >= 100:\n",
    "            scrape_data_list.append(result)\n",
    "    clean_data_with_llm_list = []\n",
    "\n",
    "    for data in scrape_data_list:\n",
    "        prompt_clean_up_temp = prompt_clean_up + data\n",
    "        clean_data = call_llm(system_clean_up, prompt_clean_up_temp, stream = False,\n",
    "                             model=clean_up_model, base_url=clean_up_base_url, api_key=clean_up_api_key)\n",
    "        clean_data_with_llm_list.append(clean_data)\n",
    "\n",
    "    extracted_text = ''\n",
    "    for counter, data in enumerate(clean_data_with_llm_list):\n",
    "        extracted_text += f'\\nSource: {counter+1}\\n'\n",
    "        extracted_text += data\n",
    "    \n",
    "    prompt_report_temp = prompt_report + extracted_text\n",
    "    report = call_llm(system_report, prompt_report_temp, stream = False,\n",
    "                             model=report_model, base_url=report_base_url, api_key=report_api_key)\n",
    "    \n",
    "    save_response_to_txt(report, folder)\n",
    "\n",
    "    return report\n",
    "\n",
    "def save_response_to_txt(report, folder):\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    counter = 0\n",
    "    file_name = ''\n",
    "    \n",
    "    while (len(file_name) > 200) | (file_name == ''):\n",
    "        file_name = report.replace('```markdown', '')\\\n",
    "          .replace('```', '').splitlines()[counter]\\\n",
    "        .replace('#', '')\\\n",
    "        .replace(':', '')\\\n",
    "        .replace('*', '').replace(\"''\", '')\n",
    "        \n",
    "        counter+= 1\n",
    "    \n",
    "    while file_name[0]==\" \":\n",
    "        file_name = file_name[1:]\n",
    "        \n",
    "    file_name = file_name.replace('_', '')\\\n",
    "                            .replace('#', '')\\\n",
    "                            .replace(':', '')\\\n",
    "                            .replace('*', '')\\\n",
    "                            .replace('/','')\\\n",
    "                            .replace('|','')\n",
    "                        \n",
    "        \n",
    "    f = open(f'{folder}/{file_name}_{now}_.txt', 'w')\n",
    "    f.write(report.replace('```markdown', '').replace('```', ''))\n",
    "    f.close()\n",
    "    \n",
    "    print(f'Saved: {folder}_{file_name}.txt \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da29897e-9b7c-4d8f-a8e1-58850986aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_clean_up = \"\"\"You are a helpful Assistance, \n",
    "                    that clean up  from a extracted text .\n",
    "                    It is very important to all include URL link.\n",
    "                    \n",
    "                    Respond in markdown. \n",
    "        \n",
    "                    It is very important to only use the extracted text \n",
    "                    and to cross check only with the extracted text \n",
    "                    and if you don't know,\n",
    "                    don't try to make up any details.\n",
    "\n",
    "                    It is very important not to summarize and provide all details.\n",
    "                    It is very important to include all URL links.\n",
    "                \"\"\"\n",
    "\n",
    "prompt_clean_up = f\"\"\"Below is an extracted text from a website. \n",
    "                        help clean up from a extracted text.\n",
    "                        \n",
    "                        that is based on the topic: {topic}\n",
    "                        \n",
    "                       extracted text:\n",
    "                   \n",
    "            \"\"\"\n",
    "\n",
    "system_report= \"\"\"You are a helpful Assistance that looks extracted text\n",
    "                Based only on the extracted text analyze extracted text and write report. \n",
    "                \n",
    "                Respond in markdown. \n",
    "\n",
    "                It is very important have list the all the URL links used at the end of the report.\n",
    "                It is very important not to say \n",
    "                \"based solely on the provided extracted text\" or \"Based on the extracted text\"\n",
    "                It is very important to be as detailed as possible.\n",
    "                It is very important to only based it only on extracted text,\n",
    "                If you don't know, don't try to make up any details\n",
    "\n",
    "                i\n",
    "                \"\"\"\n",
    "\n",
    "prompt_report = f\"\"\"Below is an extracted text, \n",
    "                    \n",
    "                    write me analyze extracted text and write report in details\n",
    "                    based on the topic: {topic}, \n",
    "                    \n",
    "                    It is very important have list the all the URL links used at the end of the report.\n",
    "                    extracted text:\n",
    "                    \n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785e63b3-30ba-49a7-a031-d247a86e1865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.keywordsai.co/blog/top-10-llm-api-providers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.keywordsai.co/blog/top-10-llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                              |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">40s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://www.keywordsai.co/blog/top-10-llm-api-providers\u001b[0m\u001b[32m                                              |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m40s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.keywordsai.co/blog/top-10-llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                              |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.</span><span style=\"color: #808000; text-decoration-color: #808000\">03</span><span style=\"color: #008000; text-decoration-color: #008000\">s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://www.keywordsai.co/blog/top-10-llm-api-providers\u001b[0m\u001b[32m                                              |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;33m0.\u001b[0m\u001b[33m03\u001b[0m\u001b[32ms \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.keywordsai.co/blog/top-10-llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                              |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">43s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://www.keywordsai.co/blog/top-10-llm-api-providers\u001b[0m\u001b[32m                                              |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m43s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/cheahjs/free-llm-api-resources\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://github.com/cheahjs/free-llm-api-resources</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">05s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://github.com/cheahjs/free-llm-api-resources\u001b[0m\u001b[32m                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m05s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://github.com/cheahjs/free-llm-api-resources</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">15s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://github.com/cheahjs/free-llm-api-resources\u001b[0m\u001b[32m                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m15s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://github.com/cheahjs/free-llm-api-resources</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">20s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://github.com/cheahjs/free-llm-api-resources\u001b[0m\u001b[32m                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m20s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194</span><span style=\"color: #008000; text-decoration-color: #008000\">                                     |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">48s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194\u001b[0m\u001b[32m                                     |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m48s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194</span><span style=\"color: #008000; text-decoration-color: #008000\">                                     |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">02s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194\u001b[0m\u001b[32m                                     |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m02s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194</span><span style=\"color: #008000; text-decoration-color: #008000\">                                     |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">50s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://medium.com/@mplsmntowers/free-api-providers-9f25b64bf194\u001b[0m\u001b[32m                                     |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m50s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.helicone.ai/blog/llm-api-providers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.helicone.ai/blog/llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                       |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">50s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://www.helicone.ai/blog/llm-api-providers\u001b[0m\u001b[32m                                                       |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m50s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.helicone.ai/blog/llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                       |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">06s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://www.helicone.ai/blog/llm-api-providers\u001b[0m\u001b[32m                                                       |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m06s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.helicone.ai/blog/llm-api-providers</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                       |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">56s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://www.helicone.ai/blog/llm-api-providers\u001b[0m\u001b[32m                                                       |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m56s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apidog.com/blog/free-open-source-llm-apis/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://apidog.com/blog/free-open-source-llm-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                   |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">19s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://apidog.com/blog/free-open-source-llm-apis/\u001b[0m\u001b[32m                                                   |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m19s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://apidog.com/blog/free-open-source-llm-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                   |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">04s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://apidog.com/blog/free-open-source-llm-apis/\u001b[0m\u001b[32m                                                   |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m04s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://apidog.com/blog/free-open-source-llm-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                   |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">23s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://apidog.com/blog/free-open-source-llm-apis/\u001b[0m\u001b[32m                                                   |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m23s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://zapier.com/blog/best-llm/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://zapier.com/blog/best-llm/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">30s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://zapier.com/blog/best-llm/\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m30s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://zapier.com/blog/best-llm/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">14s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://zapier.com/blog/best-llm/\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m14s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://zapier.com/blog/best-llm/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">44s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://zapier.com/blog/best-llm/\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m44s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://research.aimultiple.com/llm-pricing/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://research.aimultiple.com/llm-pricing/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                         |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">40s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://research.aimultiple.com/llm-pricing/\u001b[0m\u001b[32m                                                         |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m40s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://research.aimultiple.com/llm-pricing/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                         |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">07s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://research.aimultiple.com/llm-pricing/\u001b[0m\u001b[32m                                                         |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m07s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://research.aimultiple.com/llm-pricing/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                         |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">47s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://research.aimultiple.com/llm-pricing/\u001b[0m\u001b[32m                                                         |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m47s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/</span><span style=\"color: #008000; text-decoration-color: #008000\">                |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">30s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/\u001b[0m\u001b[32m                |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m30s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/</span><span style=\"color: #008000; text-decoration-color: #008000\">                |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">06s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/\u001b[0m\u001b[32m                |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m06s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/</span><span style=\"color: #008000; text-decoration-color: #008000\">                |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">36s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://www.reddit.com/r/LLMDevs/comments/1dnb3ob/llm_apis_price_comparison_by_model/\u001b[0m\u001b[32m                |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m36s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://datasciencedojo.com/blog/10-top-llm-companies/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://datasciencedojo.com/blog/10-top-llm-companies/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                               |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">41s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://datasciencedojo.com/blog/10-top-llm-companies/\u001b[0m\u001b[32m                                               |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m41s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://datasciencedojo.com/blog/10-top-llm-companies/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                               |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">15s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://datasciencedojo.com/blog/10-top-llm-companies/\u001b[0m\u001b[32m                                               |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m15s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://datasciencedojo.com/blog/10-top-llm-companies/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                               |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">56s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://datasciencedojo.com/blog/10-top-llm-companies/\u001b[0m\u001b[32m                                               |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m56s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://konfigthis.com/blog/llmops-apis/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://konfigthis.com/blog/llmops-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                             |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2.</span><span style=\"color: #008000; text-decoration-color: #008000\">37s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://konfigthis.com/blog/llmops-apis/\u001b[0m\u001b[32m                                                             |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m2.\u001b[0m\u001b[32m37s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://konfigthis.com/blog/llmops-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                             |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.</span><span style=\"color: #808000; text-decoration-color: #808000\">02</span><span style=\"color: #008000; text-decoration-color: #008000\">s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://konfigthis.com/blog/llmops-apis/\u001b[0m\u001b[32m                                                             |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;33m0.\u001b[0m\u001b[33m02\u001b[0m\u001b[32ms \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://konfigthis.com/blog/llmops-apis/</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                             |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2.</span><span style=\"color: #008000; text-decoration-color: #008000\">39s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://konfigthis.com/blog/llmops-apis/\u001b[0m\u001b[32m                                                             |\u001b[0m\n",
       "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m2.\u001b[0m\u001b[32m39s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Reports extracted_LLM API Providers and Reviews A Comprehensive Report.txt \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = get_report(topic, \n",
    "                    num_results, \n",
    "                    folder=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b3d01a6-c251-4fb5-8cbf-5ef8d182a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## LLM API Providers and Reviews: A Comprehensive Report\n",
       "\n",
       "This report analyzes the provided text to identify and review various Large Language Model (LLM) API providers. It consolidates information from multiple sources to offer a comprehensive overview of the landscape, including pricing, models offered, key features, and potential use cases.\n",
       "\n",
       "**1. Introduction**\n",
       "\n",
       "The increasing demand for AI-powered applications has led to a proliferation of LLM API providers. Choosing the right provider is crucial for developers and businesses looking to leverage the power of LLMs. This report aims to simplify the selection process by providing a detailed comparison of leading platforms.\n",
       "\n",
       "**2. Top LLM API Providers**\n",
       "\n",
       "Based on the extracted text, the following providers are identified as key players in the LLM API space:\n",
       "\n",
       "**2.1 Paid Providers**\n",
       "\n",
       "*   **Fireworks AI:**\n",
       "    *   **What:** Generative inference platform focused on speed, scalability, and production readiness. Uses the FireAttention engine.\n",
       "    *   **Why:** Low latency, stable hosting, and an active community.\n",
       "    *   **Models:** Hosts hundreds of open-source models (DeepSeek v3, Llama, Qwen, Stable Diffusion). Supports Multi-LoRA fine-tuning.\n",
       "    *   **Pricing:** Based on model size and complexity ($0.10 - $3.00 per million tokens).\n",
       "    *   **Best for:** Speed and scalability in multi-modal AI tasks.\n",
       "*   **Together AI:**\n",
       "    *   **What:** High-performance inference platform with automated optimizations for open-source LLMs.\n",
       "    *   **Why:** Streamlines development by handling infrastructure tasks (caching, load balancing).\n",
       "    *   **Models:** Supports hundreds of open-source LLMs.\n",
       "    *   **Pricing:** Pay-as-you-go.\n",
       "    *   **Best for:** Large-scale model deployment with low latency and strong privacy.\n",
       "*   **OpenRouter:**\n",
       "    *   **What:** Unified interface providing access to a wide range of AI models (open-source and commercial) through a single API.\n",
       "    *   **Why:** Flexibility to switch between LLMs.\n",
       "    *   **Models:** Access to models from OpenAI, Anthropic, Fireworks, Together AI, and more.\n",
       "    *   **Pricing:** No extra usage fees beyond the model provider's charges, plus a 5% fee on deposits.\n",
       "    *   **Best for:** Routing traffic across multiple LLMs.\n",
       "*   **Groq:**\n",
       "    *   **What:** High-speed inference platform built on LPU (Logical Processing Unit) technology.\n",
       "    *   **Why:** Fastest possible performance.\n",
       "    *   **Models:** Llama, Mistral.\n",
       "    *   **Pricing:** Token-based, geared towards enterprise use.\n",
       "    *   **Best for:** High-performance inferencing with hardware optimization.\n",
       "*   **Hugging Face:**\n",
       "    *   **What:** Open-source platform for building, training, and deploying machine learning models.\n",
       "    *   **Why:** Large model hub and support for various programming languages and cloud platforms.\n",
       "    *   **Models:** Massive catalog of open-source models.\n",
       "    *   **Pricing:** Pay-by-the-hour model for hosting on AWS or GCP.\n",
       "    *   **Best for:** Getting started with Natural Language Processing (NLP) projects.\n",
       "*   **Replicate:**\n",
       "    *   **What:** Cloud-based service for running and managing ML models.\n",
       "    *   **Why:** Quick deployment and fine-tuning without complex setup.\n",
       "    *   **Models:** Large collection of open-source models.\n",
       "    *   **Pricing:** Pay-as-you-go based on runtime.\n",
       "    *   **Best for:** Rapid prototyping and experimenting with open-source or custom models.\n",
       "*   **Perplexity AI:**\n",
       "    *   **What:** Known for intelligent search and Q&A. Offers `pplx-api` for real-time data access.\n",
       "    *   **Why:** Direct internet access for up-to-the-minute information.\n",
       "    *   **Models:** Several Llama-based models with extended context lengths.\n",
       "    *   **Pricing:** $5 per 1,000 requests, plus per-token costs ($0.20 - $5 per million tokens).\n",
       "    *   **Best for:** AI-driven search and knowledge applications.\n",
       "*   **Hyperbolic:**\n",
       "    *   **What:** Provides AI inference services and affordable GPU compute.\n",
       "    *   **Why:** Flexibility in choosing GPU power at lower costs.\n",
       "    *   **Pricing:** Charges by GPU usage.\n",
       "    *   **Best for:** Cost-effective GPU rental and API access.\n",
       "*   **Databricks:**\n",
       "    *   **What:** Unified analytics platform with its own LLM, DBRx.\n",
       "    *   **Why:** Seamless integration with existing data pipelines and support for ML/AI projects.\n",
       "    *   **Models:** Access to DBRx.\n",
       "    *   **Pricing:** Varies based on workload, storage, and compute.\n",
       "*   **Mistral:**\n",
       "    *   **What:** French company specializing in open-source LLMs. Offers flexible deployment options.\n",
       "    *   **Why:** Handles complex reasoning tasks, easy to deploy, and cost-effective.\n",
       "    *   **Models:** Mistral Large 24.11, Pixtral Large, Mistral Small 24.09, Codestral, Ministral 8B & 3B, Mistral Embed, Mistral Moderation 24.11\n",
       "    *   **Pricing:** Varies by model (input/output tokens).\n",
       "    *   **Best for:** Specialized Models.\n",
       "*   **DeepInfra:**\n",
       "    *   **What:** Cloud-based hosting of large-scale AI models.\n",
       "    *   **Why:** Easy to use, cloud-centric approach.\n",
       "    *   **Pricing:** Usage-based, billed by token or at execution time.\n",
       "    *   **Best for:** Cloud-based hosting of large-scale AI models.\n",
       "*   **Anyscale:**\n",
       "    *   **What:** Platform for scaling compute-intensive AI workloads.\n",
       "    *   **Why:** Governance, admin, and billing controls, security and privacy features.\n",
       "    *   **Pricing:** Usage-based, enterprise plans available.\n",
       "    *   **Best for:** End-to-end AI development and deployment and applications requiring high scalability.\n",
       "*   **Novita AI:**\n",
       "    *   **What:** Cloud infrastructure platform providing Model APIs and dedicated GPU resources.\n",
       "    *   **Why:** Up to 50% lower costs on model inference, globally distributed GPU network.\n",
       "    *   **Pricing:** Usage-based, billed by token or by execution time.\n",
       "    *   **Best for:** Low-cost, reliable AI model deployment with both serverless and dedicated GPU options.\n",
       "*   **Cohere:**\n",
       "    *   **What:** Provides access to Cohere's LLMs.\n",
       "    *   **Limits:** 20 requests/minute, 1,000 requests/month\n",
       "    *   **Models:** Models share a common quota. Command-A, Command-R7B, Command-R+, Command-R, Aya Expanse 8B, Aya Expanse 32B, Aya Vision 8B, Aya Vision 32B\n",
       "*   **Amazon:**\n",
       "    *   **Models:** Amazon Nova Micro, Amazon Nova Lite, and Amazon Nova Pro\n",
       "    *   **Access:** API\n",
       "\n",
       "**2.2 Free Providers**\n",
       "\n",
       "*   **OpenRouter:**\n",
       "    *   **Limits:** 20 requests/minute, 50 requests/day, 1000 requests/day with $10 lifetime top-up.\n",
       "    *   **Models:** A wide variety of open-source models.\n",
       "*   **Google AI Studio:**\n",
       "    *   **Models:** Gemini series, Gemma series.\n",
       "    *   **Note:** Data is used for training when used outside of the UK/CH/EEA/EU.\n",
       "*   **NVIDIA NIM:**\n",
       "    *   **Requirements:** Phone number verification required. Models tend to be context window limited.\n",
       "    *   **Limits:** 40 requests/minute\n",
       "    *   **Models:** Various open models.\n",
       "*   **Mistral (La Plateforme):**\n",
       "    *   **Requirements:** Free tier (Experiment plan) requires opting into data training, and phone number verification.\n",
       "    *   **Limits (per-model):** 1 request/second, 500,000 tokens/minute, 1,000,000,000 tokens/month\n",
       "    *   **Models:** Open and Proprietary Mistral models.\n",
       "*   **Mistral (Codestral):**\n",
       "    *   **Status:** Currently free to use. Monthly subscription based.\n",
       "    *   **Requirements:** Phone number verification.\n",
       "    *   **Limits:** 30 requests/minute, 2,000 requests/day\n",
       "    *   **Models:** Codestral\n",
       "*   **HuggingFace Inference Providers:**\n",
       "    *   **Note:** HuggingFace Serverless Inference limited to models smaller than 10GB. Some popular models are supported even if they exceed 10GB.\n",
       "    *   **Limits:** $0.10/month in credits\n",
       "    *   **Models:** Various open models across supported providers\n",
       "*   **Cerebras:**\n",
       "    *   **Limits:** Free tier restricted to 8K context.\n",
       "    *   **Models:** Llama series, Gemma series, DeepSeek series, Groq series, Mistral series, Qwen series, Whisper series.\n",
       "*   **Together (Free):**\n",
       "    *   **Limits:** Up to 60 requests/minute\n",
       "    *   **Models:** Llama series, DeepSeek series.\n",
       "*   **GitHub Models:**\n",
       "    *   **Limits:** Dependent on Copilot subscription tier (Free/Pro/Pro+/Business/Enterprise)\n",
       "    *   **Models:** A wide variety of open-source and proprietary models.\n",
       "*   **RunPod:**\n",
       "    *   **Description:** Distributed, decentralized crypto-based compute. Data is sent to individual hosts.\n",
       "    *   **Models:** A wide variety of open-source models.\n",
       "*   **Cloudflare Workers AI:**\n",
       "    *   **Limits:** 10,000 neurons/day\n",
       "    *   **Models:** A wide variety of open-source models.\n",
       "*   **Google Cloud Vertex AI:**\n",
       "    *   **Requirements:** Very stringent payment verification for Google Cloud.\n",
       "    *   **Models:** Gemini series, Llama series.\n",
       "\n",
       "**2.3 Providers with Trial Credits**\n",
       "\n",
       "*   **Together:** $1 credit when you add a payment method.\n",
       "*   **Fireworks:** $1 credit.\n",
       "*   **Baseten:** $5 credit when you add a payment method.\n",
       "*   **Nebius AI:** $30 credit.\n",
       "*   **Novita AI:** $0.5 for 1 year, $10 for 3 months for LLMs with referral code + GitHub account connection.\n",
       "*   **Scale AI:** $10 for 3 months.\n",
       "*   **Solar AI:** $10 for 3 months.\n",
       "*   **NLP Cloud:** $15 credit, requires phone number verification.\n",
       "*   **Alibaba Cloud (International) Model Studio:** 1 million tokens/model.\n",
       "*   **Inference.net:** $1 credit, $25 on responding to email survey.\n",
       "*   **Replicate:** $1 credit.\n",
       "*   **nCompass:** $5 credit.\n",
       "*   **Hyperbolic:** $1 credit.\n",
       "*   **SambaNova Cloud:** $5 for 3 months.\n",
       "*   **Scaleway Generative APIs:** 1,000,000 free tokens.\n",
       "\n",
       "**3. Key Considerations for Choosing an LLM API Provider**\n",
       "\n",
       "*   **Project Requirements:** Define your project's specific needs, including speed, cost, model variety, real-time data access, and security requirements.\n",
       "*   **Model Variety:** Consider the range of models offered by each provider and whether they align with your use case.\n",
       "*   **Pricing Structure:** Understand the pricing models (pay-as-you-go, subscription-based, token-based) and potential hidden costs (deposit fees, data storage).\n",
       "*   **Performance:** Evaluate the performance of different providers based on metrics like latency, throughput, and accuracy.\n",
       "*   **Ease of Use:** Assess the ease of integration and the availability of documentation and support.\n",
       "*   **Scalability:** Ensure the provider can handle your application's scaling needs.\n",
       "*   **Data Privacy and Security:** Consider the provider's data privacy policies and security measures, especially if you are dealing with sensitive data.\n",
       "\n",
       "**4. LLM Ops APIs**\n",
       "\n",
       "LLM Ops APIs are essential for businesses looking to integrate and manage LLMs effectively. They streamline development, provide monitoring and analytics, and offer tools for various aspects of the LLM lifecycle.\n",
       "\n",
       "*   **Monster API:** Single, cost-efficient API abstraction over multiple Generative AI models.\n",
       "*   **Pulze AI:** Single API that routes between different LLM providers for optimization.\n",
       "*   **Context.ai:** Focuses on performance monitoring.\n",
       "*   **Carbon:** Primarily focused on ingesting external data into LLM ecosystems.\n",
       "*   **Humanloop API:** Offers a variety of LLM Ops tools, including evaluation and monitoring, fine-tuning, and optimization.\n",
       "*   **Langfuse API:** Offers tools for managing the entire lifecycle of LLM applications: prompt management, tracing, evaluation, and metrics.\n",
       "*   **Graphlit:** Primary offering is a data ingestion tool.\n",
       "*   **DataRobot:** Comprehensive platform for building and operating LLM applications.\n",
       "*   **OpenPipe:** YC startup focused on training, deployment, fine-tuning, and evaluation of LLM models.\n",
       "*   **Autoblocks:** Platform focused on LLM evaluation: monitoring, testing, debugging, analytics, and post-deployment tools.\n",
       "\n",
       "**5. Model Comparison and Recommendations**\n",
       "\n",
       "*   **Top Models:** GPT 4o, Gemini 1.5 Pro, Claude 3.5 Sonnet.\n",
       "*   **Cost-Effective Alternatives:** Llama 3, DeepSeekV2.\n",
       "*   **General Chat/Instruction Following:** Llama 3.x Instruct, Mistral 7B Instruct, Mixtral 8x7B, Gemma 2/3 Instruct, Qwen 2.5 Instruct\n",
       "*   **Coding:** DeepSeek Coder, Qwen2.5 Coder, Llama 4 Scout/Maverick, Codestral\n",
       "*   **Multimodal (Text + Image):** Llama 3.2 Vision Instruct, Qwen 2.5 VL Instruct series, Phi-3.5 Vision, Aya Vision\n",
       "*   **Long Context Processing:** Phi-3 128k variants\n",
       "*   **High Inference Speed:** Groq\n",
       "*   **Maximum Power (via Free Tiers/Previews):** Llama 3.3 70B, Llama 3.1 405B (trials), Qwen 2.5 72B\n",
       "*   **Efficiency/Resource Constraints:** Smaller models (Llama 3.2, Phi-3 Mini, Gemma 3), quantized models (AWQ/FP8)\n",
       "\n",
       "**6. Conclusion**\n",
       "\n",
       "The LLM API landscape is dynamic and diverse, offering a wide range of options for developers and businesses. By carefully considering project requirements, evaluating provider features, and understanding pricing structures, users can make informed decisions and leverage the power of LLMs to build innovative and impactful applications.\n",
       "\n",
       "**7. URL Links**\n",
       "\n",
       "*   Together AI:\n",
       "    *   Models: <https://www.together.ai/models>\n",
       "    *   Pricing: <https://www.together.ai/pricing>\n",
       "    *   Website: <https://together.ai>\n",
       "*   Groq:\n",
       "    *   Pricing: <https://groq.com/pricing/>\n",
       "*   Hugging Face:\n",
       "    *   Pricing: <https://huggingface.co/pricing#endpoints>\n",
       "    *   Inference Providers: <https://huggingface.co/docs/inference-providers/en/index>\n",
       "*   Replicate:\n",
       "    *   Pricing: <https://replicate.com/pricing>\n",
       "    *   Website: <https://replicate.com/>\n",
       "*   Hyperbolic:\n",
       "    *   Pricing: <https://hyperbolic.xyz/pricing>\n",
       "    *   Website: <https://app.hyperbolic.xyz/>\n",
       "*   Mistral (La Plateforme): <https://console.mistral.ai/>\n",
       "*   Mistral (Codestral): <https://codestral.mistral.ai/>\n",
       "*   Cerebras: <https://cloud.cerebras.ai/>\n",
       "*   Cohere: <https://cohere.com/>\n",
       "*   GitHub Models: <https://github.com/marketplace/models>\n",
       "*   RunPod: <https://www.runpod.io/>\n",
       "*   Cloudflare Workers AI: <https://developers.cloudflare.com/workers-ai>\n",
       "*   Google Cloud Vertex AI: <https://console.cloud.google.com/vertex-ai/model-garden>\n",
       "*   Fireworks: <https://fireworks.ai/>\n",
       "*   Baseten: <https://www.baseten.co/>, <https://www.baseten.co/library/>\n",
       "*   Nebius AI: <https://studio.nebius.ai/models>\n",
       "*   Novita AI: <https://novita.ai/referral?invited_code=E5R0CA&ref=ytblmjc&utm_source=affiliate>\n",
       "*   Scale AI: <https://scale.com/>\n",
       "*   Solar AI: <https://solar.ai/>\n",
       "*   NLP Cloud: <https://nlpcloud.com/home>\n",
       "*   Alibaba Cloud (International) Model Studio: <https://bailian.console.alibabacloud.com/>\n",
       "*   Inference.net: <https://inference.net>\n",
       "*   nCompass: <https://ncompass.tech>\n",
       "*   SambaNova Cloud: <https://cloud.sambanova.ai/>\n",
       "*   Scaleway Generative APIs: <https://console.scaleway.com/generative-api/models>\n",
       "*   LLM APIs: Price Comparison by Model - r/LLMDevs: <https://medium.com/@Experto_AI/llm-apis-price-comparison-by-model-66d1c7bd259d?sk=99f3ad1216aa77ab00aa17a154cf1efb>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbb93c-1071-41fc-a0a6-1c54acb22dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
